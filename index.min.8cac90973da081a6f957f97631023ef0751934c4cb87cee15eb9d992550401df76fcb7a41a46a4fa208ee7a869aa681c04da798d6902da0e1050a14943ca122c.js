var suggestions=document.getElementById('suggestions'),userinput=document.getElementById('userinput');document.addEventListener('keydown',inputFocus);function inputFocus(a){a.keyCode===191&&(a.preventDefault(),userinput.focus()),a.keyCode===27&&(userinput.blur(),suggestions.classList.add('d-none'))}document.addEventListener('click',function(a){var b=suggestions.contains(a.target);b||suggestions.classList.add('d-none')}),document.addEventListener('keydown',suggestionFocus);function suggestionFocus(b){const d=suggestions.querySelectorAll('a'),e=[...d],a=e.indexOf(document.activeElement);let c=0;b.keyCode===38?(b.preventDefault(),c=a>0?a-1:0,d[c].focus()):b.keyCode===40&&(b.preventDefault(),c=a+1<e.length?a+1:a,d[c].focus())}(function(){var b=new FlexSearch({preset:'score',cache:!0,doc:{id:'id',field:['title','description','content'],store:['href','title','description']}}),c=[{id:0,href:"https://kubedl.io/docs/workloads/pytorch/",title:"PyTorch",description:"Run PyTorch job on Kubernetes.",content:'\u003ch2 id="example"\u003eExample\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class="language-yaml"\u003eapiVersion: training.kubedl.io/v1alpha1\nkind: \u0026quot;PyTorchJob\u0026quot;\nmetadata:\n  name: \u0026quot;pytorch-dist-sendrecv-example\u0026quot;\n  namespace: \u0026quot;kubedl\u0026quot;\nspec:\n  pytorchReplicaSpecs:\n    Master:\n      replicas: 1\n      restartPolicy: ExitCode\n      template:\n        spec:\n          containers:\n            - name: pytorch\n              image: kubedl/pytorch-dist-example\n              imagePullPolicy: Always\n    Worker:\n      replicas: 2\n      restartPolicy: ExitCode\n      template:\n        spec:\n          containers:\n            - name: pytorch\n              image: kubedl/pytorch-dist-example\n              imagePullPolicy: Always\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id="spec"\u003eSpec\u003c/h2\u003e\n\u003cp\u003eCheck the CRD definition. \u003ca href="https://github.com/alibaba/kubedl/blob/master/apis/training/v1alpha1/pytorchjob_types.go"\u003eGo -\u0026gt;\u003c/a\u003e\u003c/p\u003e\n'},{id:1,href:"https://kubedl.io/docs/prologue/introduction/",title:"Introduction",description:"KubeDL runs your deep learning workloads on Kubernetes.",content:'\u003cp\u003eCurrently, KubeDL supports running \u003ca href="https://github.com/tensorflow/tensorflow"\u003eTensorFlow\u003c/a\u003e, \u003ca href="https://github.com/pytorch/pytorch"\u003ePyTorch\u003c/a\u003e,\n\u003ca href="https://github.com/dmlc/xgboost"\u003eXGBoost\u003c/a\u003e, \u003ca href="https://github.com/mars-project/mars"\u003eMars\u003c/a\u003e and MPI distributed training jobs on Kubernetes.\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class="img-fluid lazyload blur-up" data-sizes="auto" src="https://kubedl.io/docs/prologue/introduction/introduction_hufa79e617da320aec9287bf6111103a76_60530_20x0_resize_box_2.png" data-srcset="https://kubedl.io/docs/prologue/introduction/introduction_hufa79e617da320aec9287bf6111103a76_60530_900x0_resize_box_2.png 900w,https://kubedl.io/docs/prologue/introduction/introduction_hufa79e617da320aec9287bf6111103a76_60530_800x0_resize_box_2.png 800w,https://kubedl.io/docs/prologue/introduction/introduction_hufa79e617da320aec9287bf6111103a76_60530_700x0_resize_box_2.png 700w,https://kubedl.io/docs/prologue/introduction/introduction_hufa79e617da320aec9287bf6111103a76_60530_600x0_resize_box_2.png 600w,https://kubedl.io/docs/prologue/introduction/introduction_hufa79e617da320aec9287bf6111103a76_60530_500x0_resize_box_2.png 500w" width="706" height="531" alt="introduction"\u003e\n  \u003cnoscript\u003e\u003cimg class="img-fluid" sizes="100vw" srcset="https://kubedl.io/docs/prologue/introduction/introduction_hufa79e617da320aec9287bf6111103a76_60530_900x0_resize_box_2.png 900w,https://kubedl.io/docs/prologue/introduction/introduction_hufa79e617da320aec9287bf6111103a76_60530_800x0_resize_box_2.png 800w,https://kubedl.io/docs/prologue/introduction/introduction_hufa79e617da320aec9287bf6111103a76_60530_700x0_resize_box_2.png 700w,https://kubedl.io/docs/prologue/introduction/introduction_hufa79e617da320aec9287bf6111103a76_60530_600x0_resize_box_2.png 600w,https://kubedl.io/docs/prologue/introduction/introduction_hufa79e617da320aec9287bf6111103a76_60530_500x0_resize_box_2.png 500w" src="https://kubedl.io/docs/prologue/introduction/introduction.png" width="706" height="531" alt="introduction"\u003e\u003c/noscript\u003e\n  \u003cfigcaption class="figure-caption"\u003eIntroduction\u003c/figcaption\u003e\n\u003c/figure\u003e\n\n\u003ch2 id="key-features"\u003eKey Features\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eSupport different kinds of deep learning training jobs in a single controller. You don\u0026rsquo;t need to run each controller for each job kind.\u003c/li\u003e\n\u003cli\u003eExpose unified \u003ca href="https://kubedl.io/docs/references/metrics/"\u003eprometheus metrics\u003c/a\u003e for job stats.\u003c/li\u003e\n\u003cli\u003eSave job metadata and events in external storage such as Mysql or certain event DB to outlive api-server state.\u003c/li\u003e\n\u003cli\u003e\u003ca href="https://kubedl.io/docs/recipes/code-sync/"\u003eSync files\u003c/a\u003e on container launch. You no longer need to rebuild the image to include the modified code every time.\u003c/li\u003e\n\u003cli\u003eRun jobs with host network for performance or nvlink communication across containers.\u003c/li\u003e\n\u003cli\u003eSupport advanced scheduling features such as gang scheduling.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id="get-started"\u003eGet started\u003c/h2\u003e\n\u003cp\u003eThere are two main ways to install KubeDL.\u003c/p\u003e\n\u003ch3 id="install-using-helm"\u003eInstall using Helm\u003c/h3\u003e\n\u003cp\u003eInstall KubeDL using Helm charts. \u003ca href="https://kubedl.io/docs/prologue/install-using-helm/"\u003eGo →\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id="install-using-yaml-files"\u003eInstall using YAML files\u003c/h3\u003e\n\u003cp\u003eInstall KubeDL using YAML files. \u003ca href="https://kubedl.io/docs/prologue/quick-start/"\u003eGo →\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id="recipes"\u003eRecipes\u003c/h2\u003e\n\u003cp\u003eGet instructions on how to accomplish common tasks with KubeDL. \u003ca href="https://getdoks.org/docs/recipes/project-configuration/"\u003eRecipes →\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id="reference"\u003eReference\u003c/h2\u003e\n\u003cp\u003eReferences for apis, metrics etc. \u003ca href="https://kubedl.io/docs/references/"\u003eReference →\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id="contributing"\u003eContributing\u003c/h2\u003e\n\u003cp\u003eFind out how to contribute to KubeDL. \u003ca href="https://kubedl.io/docs/contributing/how-to-contribute/"\u003eContributing →\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id="help"\u003eHelp\u003c/h2\u003e\n\u003cp\u003eGet help on KubeDL. \u003ca href="https://kubedl.io/docs/help/"\u003eHelp →\u003c/a\u003e\u003c/p\u003e\n'},{id:2,href:"https://kubedl.io/docs/prologue/",title:"Prologue",description:"Prologue KubeDL.",content:""},{id:3,href:"https://kubedl.io/docs/references/metrics/",title:"Metrics",description:"",content:"\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eMetric Names\u003c/th\u003e\n\u003cth\u003elabel\u003c/th\u003e\n\u003cth\u003eDescription\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003ekubedl_jobs_created\u003c/td\u003e\n\u003ctd\u003ekind\u003c/td\u003e\n\u003ctd\u003eCounts number of jobs created\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ekubedl_jobs_deleted\u003c/td\u003e\n\u003ctd\u003ekind\u003c/td\u003e\n\u003ctd\u003eCounts number of jobs deleted\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ekubedl_jobs_successful\u003c/td\u003e\n\u003ctd\u003ekind\u003c/td\u003e\n\u003ctd\u003eCounts number of jobs successfully finished\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ekubedl_jobs_failed\u003c/td\u003e\n\u003ctd\u003ekind\u003c/td\u003e\n\u003ctd\u003eCounts number of jobs failed\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ekubedl_jobs_restarted\u003c/td\u003e\n\u003ctd\u003ekind\u003c/td\u003e\n\u003ctd\u003eCounts number of jobs restarted\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ekubedl_jobs_running\u003c/td\u003e\n\u003ctd\u003ekind\u003c/td\u003e\n\u003ctd\u003eCounts number of jobs currently running\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ekubedl_jobs_pending\u003c/td\u003e\n\u003ctd\u003ekind\u003c/td\u003e\n\u003ctd\u003eCounts number of jobs currently pending\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ekubedl_jobs_first_pod_launch_delay_seconds\u003c/td\u003e\n\u003ctd\u003ekind, name, namespace, uid\u003c/td\u003e\n\u003ctd\u003eHistogram for recording launch delay duration (from job created to first pod running)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ekubedl_jobs_all_pods_launch_delay_seconds\u003c/td\u003e\n\u003ctd\u003ekind, name, namespace, uid\u003c/td\u003e\n\u003ctd\u003eHistogram for recording launch delay duration (from job created to all pods running)\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u003ccode\u003elabel\u003c/code\u003e specifics the labels supported for the corresponding prometheus metrics\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ekind\u003c/code\u003e - the target job kind, e.g. TFJob, PyTorchJob, MarsJob, XGBoostJob\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ename\u003c/code\u003e - the name of the job\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003enamespace\u003c/code\u003e - the namespace of the job\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003euid\u003c/code\u003e - the uid of the job\u003c/li\u003e\n\u003c/ul\u003e\n"},{id:4,href:"https://kubedl.io/docs/recipes/code-sync/",title:"File Sync",description:"Sync files on container launch.",content:'\u003cp\u003eKubeDL supports syncing files from remote on container launch.\nUser can modify the code, reference the code repository and run the jobs without re-building the image every time to include the modified code.\u003c/p\u003e\n\u003cp\u003eCurrently, only support downloading from github. The implementation is pluggable and can easily support other distributed filesystem like HDFS.\u003c/p\u003e\n\u003ch3 id="git-hub"\u003eGit Hub\u003c/h3\u003e\n\u003cp\u003eUsers can set the git config in the job\u0026rsquo;s annotation with key \u003ccode\u003ekubedl.io/git-sync-config\u003c/code\u003e as below. The git repo will be\ndownloaded and saved in the container\u0026rsquo;s \u003ccode\u003eworking dir\u003c/code\u003e by default. Please use the git repo\u0026rsquo;s clone url ending with the \u003ccode\u003e.git\u003c/code\u003e,\nrather than the git repo\u0026rsquo;s web url.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-yaml"\u003e    apiVersion: \u0026quot;training.kubedl.io/v1alpha1\u0026quot;\n    kind: \u0026quot;TFJob\u0026quot;\n    metadata:\n      name: \u0026quot;mnist\u0026quot;\n      namespace: kubedl\n      annotations:\n +      kubedl.io/git-sync-config: \'{\u0026quot;source\u0026quot;: \u0026quot;https://github.com/alibaba/kubedl.git\u0026quot; }\'\n    spec:\n      cleanPodPolicy: None\n      tfReplicaSpecs:\n        ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eA full list of supported options are:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-json"\u003e{\n    \u0026quot;source\u0026quot;: \u0026quot;https://github.com/sample/sample.git\u0026quot;,  // code source (required).\n    \u0026quot;image\u0026quot;: \u0026quot;xxx\u0026quot;,     // the image to execute the git-sync logic (optional).\n    \u0026quot;rootPath\u0026quot;: \u0026quot;xxx\u0026quot;,  // the path to save downloaded files (optional).\n    \u0026quot;destPath\u0026quot;: \u0026quot;xxx\u0026quot;,  // the name of (a symlink to) a directory in which to check-out files (optional).\n    \u0026quot;envs\u0026quot;: [],         // user-customized environment variables (optional).\n    \u0026quot;branch\u0026quot;: \u0026quot;xxx\u0026quot;,    // git repo branch (optional).\n    \u0026quot;revison\u0026quot;: \u0026quot;xxx\u0026quot;,   // git repo commit revision (optional).\n    \u0026quot;depth\u0026quot;: \u0026quot;xxx\u0026quot;,     // git sync depth (optional).\n    \u0026quot;maxFailures\u0026quot; : 3,  // max consecutive failures allowed (optional).\n    \u0026quot;ssh\u0026quot;: false,       // use ssh mode or not (optional).\n    \u0026quot;sshFile\u0026quot;: \u0026quot;xxx\u0026quot;,   // ssh file path (optional).\n    \u0026quot;user\u0026quot;: \u0026quot;xxx\u0026quot;,      // git config username (optional).\n    \u0026quot;password\u0026quot;: \u0026quot;xxx\u0026quot;   // git config password (optional).\n}\n\u003c/code\u003e\u003c/pre\u003e\n'},{id:5,href:"https://kubedl.io/docs/recipes/hostnetwork/",title:"Host Network",description:"Run jobs with host network",content:'\u003ch2 id="background"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eNetwork bandwidth is a bottleneck resource for communication-intensive jobs. Host mode networking can be useful to optimize\nperformance. In addition, other scenarios (e.g: nvlink communications between containerized gpu processes) may depend on\nhost-network as well.\u003c/p\u003e\n\u003ch2 id="how-to-use"\u003eHow To Use\u003c/h2\u003e\n\u003cp\u003eKubeDL provides a feature-gate to enable \u003ccode\u003ehostnetwork\u003c/code\u003e mode for jobs. Users only need to add an annotation\n\u003ccode\u003ekubedl.io/network-mode: host\u003c/code\u003e to the job specifications, for example:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-yaml"\u003e    apiVersion: \u0026quot;training.kubedl.io/v1alpha1\u0026quot;\n    kind: \u0026quot;TFJob\u0026quot;\n    metadata:\n      name: \u0026quot;mnist\u0026quot;\n      namespace: kubedl\n      annotations:\n +      kubedl.io/network-mode: \'host\'\n    spec:\n      cleanPodPolicy: None\n      tfReplicaSpecs:\n        Worker:\n          replicas: 3\n          ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id="design"\u003eDesign\u003c/h2\u003e\n\u003cp\u003eThe essence of \u003ccode\u003ehostnetwork-mode\u003c/code\u003e is to randomize container ports to avoid port collision and enable service discovery\nacross workers. KubeDL achieves by following steps:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eEnable \u003ccode\u003ehostnetwork\u003c/code\u003e in \u003ccode\u003ePod\u003c/code\u003e spec and set DNS policy as \u003ccode\u003eClusterFirstWithHostNet\u003c/code\u003e;\u003c/li\u003e\n\u003cli\u003eChoose a random port as container port.\u003c/li\u003e\n\u003cli\u003eChange \u003ccode\u003eTargetPort\u003c/code\u003e of corresponding worker\u0026rsquo;s \u003ccode\u003eService\u003c/code\u003e to the previous randomized port, and set \u003ccode\u003eCluterIP\u003c/code\u003e as empty string(instead of \u003ccode\u003eNone\u003c/code\u003e), so that kube-proxy will be able to forward traffic from \u003ccode\u003ePort\u003c/code\u003e to \u003ccode\u003eTargetPort\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eChange the job cluster spec (e.g. the \u003ccode\u003eTF_CONFIG\u003c/code\u003e) .\u003c/li\u003e\n\u003cli\u003eHandle worker fail-over and use latest available port as the \u003ccode\u003eTargetPort\u003c/code\u003e in the new worker.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eHere is a Tensorflow job example:\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class="img-fluid lazyload blur-up" data-sizes="auto" src="https://kubedl.io/docs/recipes/hostnetwork/tf_hostnetwork_hu3231db9fe621f8cd4234a60c2aad43b9_63572_20x0_resize_box_2.png" data-srcset="https://kubedl.io/docs/recipes/hostnetwork/tf_hostnetwork_hu3231db9fe621f8cd4234a60c2aad43b9_63572_900x0_resize_box_2.png 900w,https://kubedl.io/docs/recipes/hostnetwork/tf_hostnetwork_hu3231db9fe621f8cd4234a60c2aad43b9_63572_800x0_resize_box_2.png 800w,https://kubedl.io/docs/recipes/hostnetwork/tf_hostnetwork_hu3231db9fe621f8cd4234a60c2aad43b9_63572_700x0_resize_box_2.png 700w,https://kubedl.io/docs/recipes/hostnetwork/tf_hostnetwork_hu3231db9fe621f8cd4234a60c2aad43b9_63572_600x0_resize_box_2.png 600w,https://kubedl.io/docs/recipes/hostnetwork/tf_hostnetwork_hu3231db9fe621f8cd4234a60c2aad43b9_63572_500x0_resize_box_2.png 500w" width="912" height="472" alt="tf_hostnetwork"\u003e\n  \u003cnoscript\u003e\u003cimg class="img-fluid" sizes="100vw" srcset="https://kubedl.io/docs/recipes/hostnetwork/tf_hostnetwork_hu3231db9fe621f8cd4234a60c2aad43b9_63572_900x0_resize_box_2.png 900w,https://kubedl.io/docs/recipes/hostnetwork/tf_hostnetwork_hu3231db9fe621f8cd4234a60c2aad43b9_63572_800x0_resize_box_2.png 800w,https://kubedl.io/docs/recipes/hostnetwork/tf_hostnetwork_hu3231db9fe621f8cd4234a60c2aad43b9_63572_700x0_resize_box_2.png 700w,https://kubedl.io/docs/recipes/hostnetwork/tf_hostnetwork_hu3231db9fe621f8cd4234a60c2aad43b9_63572_600x0_resize_box_2.png 600w,https://kubedl.io/docs/recipes/hostnetwork/tf_hostnetwork_hu3231db9fe621f8cd4234a60c2aad43b9_63572_500x0_resize_box_2.png 500w" src="https://kubedl.io/docs/recipes/hostnetwork/tf_hostnetwork.png" width="912" height="472" alt="tf_hostnetwork"\u003e\u003c/noscript\u003e\n  \u003cfigcaption class="figure-caption"\u003etensorflow hostnetwork\u003c/figcaption\u003e\n\u003c/figure\u003e\n\n'},{id:6,href:"https://kubedl.io/docs/workloads/tensorflow/",title:"TensorFlow",description:"Run Tensorflow on Kubernetes.",content:'\u003ch2 id="example"\u003eExample\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class="language-yaml"\u003eapiVersion: training.kubedl.io/v1alpha1\nkind: \u0026quot;TFJob\u0026quot;\nmetadata:\n  name: \u0026quot;mnist\u0026quot;\n  namespace: kubedl\nspec:\n  cleanPodPolicy: None\n  tfReplicaSpecs:\n    Worker:\n      replicas: 1\n      restartPolicy: Never\n      template:\n        spec:\n          containers:\n            - name: tensorflow\n              image: kubedl/tf-mnist-with-summaries:1.0\n              command:\n                - \u0026quot;python\u0026quot;\n                - \u0026quot;/var/tf_mnist/mnist_with_summaries.py\u0026quot;\n                - \u0026quot;--log_dir=/train/logs\u0026quot;\n                - \u0026quot;--learning_rate=0.01\u0026quot;\n                - \u0026quot;--batch_size=150\u0026quot;\n              volumeMounts:\n                - mountPath: \u0026quot;/train\u0026quot;\n                  name: \u0026quot;training\u0026quot;\n              resources:\n                limits:\n                  cpu: 2048m\n                  memory: 2Gi\n                requests:\n                  cpu: 1024m\n                  memory: 1Gi\n          volumes:\n            - name: \u0026quot;training\u0026quot;\n              hostPath:\n                path: /tmp/data\n                type: DirectoryOrCreate\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id="spec"\u003eSpec\u003c/h2\u003e\n\u003cp\u003eCheck the CRD definition. \u003ca href="https://github.com/alibaba/kubedl/blob/master/apis/training/v1alpha1/tfjob_types.go"\u003eGo -\u0026gt;\u003c/a\u003e\u003c/p\u003e\n'},{id:7,href:"https://kubedl.io/docs/references/flags/",title:"Startup flags",description:"KubeDL startup flags",content:"\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eFlag Name\u003c/th\u003e\n\u003cth\u003eDescription\u003c/th\u003e\n\u003cth\u003eDefault\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003econtroller-metrics-addr\u003c/td\u003e\n\u003ctd\u003eThe prometheus metrics endpoint for job stats\u003c/td\u003e\n\u003ctd\u003e8088\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eenable-leader-election\u003c/td\u003e\n\u003ctd\u003eEnable leader election for controller manager. Enabling this will ensure there is only one active controller manager.\u003c/td\u003e\n\u003ctd\u003efalse\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003egang-scheduler-name\u003c/td\u003e\n\u003ctd\u003eThe name of gang scheduler, by default it is set to empty meaning not enalbing gang scheduling\u003c/td\u003e\n\u003ctd\u003e\u0026quot;\u0026quot;\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003emax-reconciles\u003c/td\u003e\n\u003ctd\u003eThe number of max concurrent reconciles of each controller\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n"},{id:8,href:"https://kubedl.io/docs/contributing/how-to-contribute/",title:"How to Contribute",description:"You are very welcome to contribute to KubeDL",content:'\u003ch1 id="contributing-to-kubedl"\u003eContributing to KubeDL\u003c/h1\u003e\n\u003cp\u003eWelcome to KubeDL!\nWe encourage you to help out by reporting issues, improving documentation, fixing bugs, or adding new features.\nPlease also take a look at our code of conduct, which details how contributors are expected to conduct themselves as part of the KubeDL community.\u003c/p\u003e\n\u003ch2 id="reporting-issues"\u003eReporting issues\u003c/h2\u003e\n\u003cp\u003eTo be honest, we regard every user of KubeDL as a very kind contributor.\nAfter experiencing KubeDL, you may have some feedback for the project.\nThen feel free to open an issue.\u003c/p\u003e\n\u003cp\u003eThere are lot of cases when you could open an issue:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ebug report\u003c/li\u003e\n\u003cli\u003efeature request\u003c/li\u003e\n\u003cli\u003eperformance issues\u003c/li\u003e\n\u003cli\u003efeature proposal\u003c/li\u003e\n\u003cli\u003efeature design\u003c/li\u003e\n\u003cli\u003ehelp wanted\u003c/li\u003e\n\u003cli\u003edoc incomplete\u003c/li\u003e\n\u003cli\u003etest improvement\u003c/li\u003e\n\u003cli\u003eany questions on project\u003c/li\u003e\n\u003cli\u003eand so on\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAlso we must remind that when filing a new issue, please remember to remove the sensitive data from your post.\nSensitive data could be password, secret key, network locations, private business data and so on.\u003c/p\u003e\n\u003ch2 id="code-and-doc-contribution"\u003eCode and doc contribution\u003c/h2\u003e\n\u003cp\u003eEvery action to make KubeDL better is encouraged.\nOn GitHub, every improvement for KubeDL could be via a PR (short for pull request).\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIf you find a typo, try to fix it!\u003c/li\u003e\n\u003cli\u003eIf you find a bug, try to fix it!\u003c/li\u003e\n\u003cli\u003eIf you find some redundant codes, try to remove them!\u003c/li\u003e\n\u003cli\u003eIf you find some test cases missing, try to add them!\u003c/li\u003e\n\u003cli\u003eIf you could enhance a feature, please DO NOT hesitate!\u003c/li\u003e\n\u003cli\u003eIf you find code implicit, try to add comments to make it clear!\u003c/li\u003e\n\u003cli\u003eIf you find code ugly, try to refactor that!\u003c/li\u003e\n\u003cli\u003eIf you can help to improve documents, it could not be better!\u003c/li\u003e\n\u003cli\u003eIf you find document incorrect, just do it and fix that!\u003c/li\u003e\n\u003cli\u003e\u0026hellip;\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id="workspace-preparation"\u003eWorkspace Preparation\u003c/h3\u003e\n\u003cp\u003eTo put forward a PR, we assume you have registered a GitHub ID.\nThen you could finish the preparation in the following steps:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eFork\u003c/strong\u003e Fork the repository you wish to work on. You just need to click the button Fork in right-left of project repository main page. Then you will end up with your repository in your GitHub username.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eClone\u003c/strong\u003e your own repository to develop locally. Use \u003ccode\u003egit clone https://github.com/\u0026lt;your-username\u0026gt;/kubedl.git\u003c/code\u003e to clone repository to your local machine. Then you can create new branches to finish the change you wish to make.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSet remote\u003c/strong\u003e upstream to be \u003ccode\u003ehttps://github.com/alibaba/kubedl.git\u003c/code\u003e using the following two commands:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003egit remote add upstream https://github.com/alibaba/kubedl.git\ngit remote set-url --push upstream no-pushing\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAdding this, we can easily synchronize local branches with upstream branches.\u003c/p\u003e\n\u003col start="4"\u003e\n\u003cli\u003e\u003cstrong\u003eCreate a branch\u003c/strong\u003e to add a new feature or fix issues\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eUpdate local working directory:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003ecd \u0026lt;project\u0026gt;\ngit fetch upstream\ngit checkout master\ngit rebase upstream/master\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eCreate a new branch:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003egit checkout -b \u0026lt;new-branch\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eMake any change on the new-branch then build and test your codes.\u003c/p\u003e\n\u003ch3 id="pr-description"\u003ePR Description\u003c/h3\u003e\n\u003cp\u003ePR is the only way to make change to KubeDL project files.\nTo help reviewers better get your purpose, PR description could not be too detailed.\u003c/p\u003e\n\u003ch3 id="developing-environment"\u003eDeveloping Environment\u003c/h3\u003e\n\u003cp\u003eAs a contributor, if you want to make any contribution to KubeDL project, we should reach an agreement on the version of tools used in the development environment.\nHere are some dependents with specific version:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eGolang : v1.13+ (1.14 is best)\u003c/li\u003e\n\u003cli\u003eKubernetes: v1.12+\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id="developing-guide"\u003eDeveloping guide\u003c/h3\u003e\n\u003cp\u003eKubeDL uses \u003ca href="https://github.com/kubernetes-sigs/kubebuilder"\u003eKubeBuilder\u003c/a\u003e for scaffolding code.\u003c/p\u003e\n\u003cp\u003eThere\u0026rsquo;s a \u003ccode\u003eMakefile\u003c/code\u003e in the root folder which describes the options to build and install. Here are some common ones:\u003c/p\u003e\n\u003ch4 id="build-the-binary"\u003eBuild the binary\u003c/h4\u003e\n\u003cdiv class="doks-clipboard"\u003e\n  \u003cbutton class="btn-clipboard btn btn-link" data-clipboard-text="make manager"\u003e\u003cspan class="copy-status"\u003e\u003c/span\u003e\u003c/button\u003e\n\u003c/div\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003emake manager\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4 id="run-the-tests"\u003eRun the tests\u003c/h4\u003e\n\u003cdiv class="doks-clipboard"\u003e\n  \u003cbutton class="btn-clipboard btn btn-link" data-clipboard-text="make test"\u003e\u003cspan class="copy-status"\u003e\u003c/span\u003e\u003c/button\u003e\n\u003c/div\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003emake test\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4 id="generate-manifests-crd-rbac-yaml-files-etc"\u003eGenerate manifests: CRD, RBAC YAML files etc\u003c/h4\u003e\n\u003cdiv class="doks-clipboard"\u003e\n  \u003cbutton class="btn-clipboard btn btn-link" data-clipboard-text="make manifests"\u003e\u003cspan class="copy-status"\u003e\u003c/span\u003e\u003c/button\u003e\n\u003c/div\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003emake manifests\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4 id="build-the-docker-image"\u003eBuild the docker image\u003c/h4\u003e\n\u003cp\u003eReplace the image name to your own image\u003c/p\u003e\n\u003cdiv class="doks-clipboard"\u003e\n  \u003cbutton class="btn-clipboard btn btn-link" data-clipboard-text="export IMG=kubedl/kubedl:v0.3.0 \u0026\u0026 make docker-build"\u003e\u003cspan class="copy-status"\u003e\u003c/span\u003e\u003c/button\u003e\n\u003c/div\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003eexport IMG=kubedl/kubedl:v0.3.0 \u0026amp;\u0026amp; make docker-build\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4 id="push-the-image"\u003ePush the image\u003c/h4\u003e\n\u003cp\u003eChange the image name to your own image.\n\u003cdiv class="doks-clipboard"\u003e\n  \u003cbutton class="btn-clipboard btn btn-link" data-clipboard-text="docker push kubedl/kubedl:v0.3.0"\u003e\u003cspan class="copy-status"\u003e\u003c/span\u003e\u003c/button\u003e\n\u003c/div\u003e\n\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003edocker push kubedl/kubedl:v0.3.0\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id="engage-to-help-anything"\u003eEngage to help anything\u003c/h2\u003e\n\u003cp\u003eWe choose GitHub as the primary place for KubeDL to collaborate.\nSo the latest updates of KubeDL are always here.\nAlthough contributions via PR is an explicit way to help, we still call for any other ways.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ereply to other\u0026rsquo;s issues if you could;\u003c/li\u003e\n\u003cli\u003ehelp solve other user\u0026rsquo;s problems;\u003c/li\u003e\n\u003cli\u003ehelp review other\u0026rsquo;s PR design;\u003c/li\u003e\n\u003cli\u003ehelp review other\u0026rsquo;s codes in PR;\u003c/li\u003e\n\u003cli\u003ediscuss about KubeDL to make things clearer;\u003c/li\u003e\n\u003cli\u003eadvocate KubeDL technology beyond GitHub;\u003c/li\u003e\n\u003cli\u003ewrite blogs on KubeDL and so on.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIn a word, \u003cstrong\u003eANY HELP IS CONTRIBUTION\u003c/strong\u003e.\u003c/p\u003e\n\u003ch2 id="join-kubedl-as-a-member"\u003eJoin KubeDL as a member\u003c/h2\u003e\n\u003cp\u003eIt is also welcomed to join KubeDL team if you are willing to participate in KubeDL community continuously and keep active.\u003c/p\u003e\n\u003ch3 id="requirements"\u003eRequirements\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eHave read the \u003ca href="./CONTRIBUTING.md"\u003eContributing to KubeDL\u003c/a\u003e carefully\u003c/li\u003e\n\u003cli\u003eHave read the \u003ca href="./CODE_OF_CONDUCT.md"\u003eContributor Covenant Code of Conduct\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eHave submitted multi PRs to the community\u003c/li\u003e\n\u003cli\u003eBe active in the community, may including but not limited\n\u003cul\u003e\n\u003cli\u003eSubmitting or commenting on issues\u003c/li\u003e\n\u003cli\u003eContributing PRs to the community\u003c/li\u003e\n\u003cli\u003eReviewing PRs in the community\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id="how-to-do-it"\u003eHow to do it\u003c/h3\u003e\n\u003cp\u003eYou can do it in either of two ways:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSubmit a PR in the project repo\u003c/li\u003e\n\u003cli\u003eContact via the \u003ca href="./README.md#community"\u003ecommunity\u003c/a\u003e channels offline\u003c/li\u003e\n\u003c/ul\u003e\n'},{id:9,href:"https://kubedl.io/docs/prologue/install-using-helm/",title:"Install Using Helm",description:"Install KubeDL using Helm",content:'\u003ch2 id="install-helm"\u003eInstall Helm\u003c/h2\u003e\n\u003cp\u003eHelm is a package manager for Kubernetes. You can install helm with command below on MacOS\u003c/p\u003e\n\u003cdiv class="doks-clipboard"\u003e\n  \u003cbutton class="btn-clipboard btn btn-link" data-clipboard-text="brew install helm"\u003e\u003cspan class="copy-status"\u003e\u003c/span\u003e\u003c/button\u003e\n\u003c/div\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003ebrew install helm\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eCheck the \u003ca href="https://helm.sh/docs/intro/install/"\u003ehelm website\u003c/a\u003e for more details.\u003c/p\u003e\n\u003ch2 id="install-kubedl"\u003eInstall KubeDL\u003c/h2\u003e\n\u003cp\u003eFrom the root directory, run\u003c/p\u003e\n\u003cdiv class="doks-clipboard"\u003e\n  \u003cbutton class="btn-clipboard btn btn-link" data-clipboard-text="helm install kubedl ./helm/kubedl --create-namespace -n kubedl-system"\u003e\u003cspan class="copy-status"\u003e\u003c/span\u003e\u003c/button\u003e\n\u003c/div\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003ehelm install kubedl ./helm/kubedl --create-namespace -n kubedl-system\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou can override default values defined in \u003ca href="https://github.com/alibaba/kubedl/blob/master/helm/kubedl/values.yaml"\u003evalues.yaml\u003c/a\u003e with \u003ccode\u003e--set\u003c/code\u003e flag.\nFor example, set the custom cpu/memory resource:\u003c/p\u003e\n\u003cdiv class="doks-clipboard"\u003e\n  \u003cbutton class="btn-clipboard btn btn-link" data-clipboard-text="helm install kubedl ./helm/kubedl --create-namespace -n kubedl-system --set resources.requests.cpu=1024m --set resources.requests.memory=2Gi"\u003e\u003cspan class="copy-status"\u003e\u003c/span\u003e\u003c/button\u003e\n\u003c/div\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003ehelm install kubedl ./helm/kubedl --create-namespace -n kubedl-system  --set resources.requests.cpu=1024m --set resources.requests.memory=2Gi\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eHelm will install CRDs and KubeDL controller under \u003ccode\u003ekubedl-system\u003c/code\u003e namespace.\u003c/p\u003e\n\u003ch2 id="uninstall-kubedl"\u003eUninstall KubeDL\u003c/h2\u003e\n\u003cdiv class="doks-clipboard"\u003e\n  \u003cbutton class="btn-clipboard btn btn-link" data-clipboard-text="helm uninstall kubedl -n kubedl-system"\u003e\u003cspan class="copy-status"\u003e\u003c/span\u003e\u003c/button\u003e\n\u003c/div\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003ehelm uninstall kubedl -n kubedl-system\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id="delete-crds"\u003eDelete CRDs\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl delete crd elasticdljobs.training.kubedl.io marsjobs.training.kubedl.io mpijobs.training.kubedl.io pytorchjobs.training.kubedl.io tfjobs.training.kubedl.io xdljobs.training.kubedl.io xgboostjobs.training.kubedl.io\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id="enable-specific-job-kind"\u003eEnable specific job Kind\u003c/h2\u003e\n\u003cp\u003eKubeDL supports all kinds of jobs(tensorflow, pytorch etc.) in a single Kubernetes operator. You can selectively enable the kind of jobs to support.\nThere are three options:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eDefault option. Just install the job CRDs required. KubeDL will automatically enable the corresponding job controller.\u003c/li\u003e\n\u003cli\u003eSet env \u003ccode\u003eWORKLOADS_ENABLE\u003c/code\u003e in KubeDL container. The value is a list of job types to be enabled. For example, \u003ccode\u003eWORKLOADS_ENABLE=TFJob,PytorchJob\u003c/code\u003e means only Tensorflow and Pytorch Job are enabled.\u003c/li\u003e\n\u003cli\u003eSet startup flags \u003ccode\u003e--workloads\u003c/code\u003e in KubeDL container command args. The value is a list of job types to be enabled like \u003ccode\u003e--workloads TFJob,PytorchJob\u003c/code\u003e.\u003c/li\u003e\n\u003c/ol\u003e\n'},{id:10,href:"https://kubedl.io/docs/workloads/",title:"Workloads",description:"Workloads",content:""},{id:11,href:"https://kubedl.io/docs/contributing/code-of-conduct/",title:"Code of Conduct",description:"code of conduct",content:'\u003ch2 id="our-pledge"\u003eOur Pledge\u003c/h2\u003e\n\u003cp\u003eWe as members, contributors, and leaders pledge to make participation in our\ncommunity a harassment-free experience for everyone, regardless of age, body\nsize, visible or invisible disability, ethnicity, sex characteristics, gender\nidentity and expression, level of experience, education, socio-economic status,\nnationality, personal appearance, race, religion, or sexual identity\nand orientation.\u003c/p\u003e\n\u003cp\u003eWe pledge to act and interact in ways that contribute to an open, welcoming,\ndiverse, inclusive, and healthy community.\u003c/p\u003e\n\u003ch2 id="our-standards"\u003eOur Standards\u003c/h2\u003e\n\u003cp\u003eExamples of behavior that contributes to a positive environment for our\ncommunity include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDemonstrating empathy and kindness toward other people\u003c/li\u003e\n\u003cli\u003eBeing respectful of differing opinions, viewpoints, and experiences\u003c/li\u003e\n\u003cli\u003eGiving and gracefully accepting constructive feedback\u003c/li\u003e\n\u003cli\u003eAccepting responsibility and apologizing to those affected by our mistakes,\nand learning from the experience\u003c/li\u003e\n\u003cli\u003eFocusing on what is best not just for us as individuals, but for the\noverall community\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eExamples of unacceptable behavior include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe use of sexualized language or imagery, and sexual attention or\nadvances of any kind\u003c/li\u003e\n\u003cli\u003eTrolling, insulting or derogatory comments, and personal or political attacks\u003c/li\u003e\n\u003cli\u003ePublic or private harassment\u003c/li\u003e\n\u003cli\u003ePublishing others\' private information, such as a physical or email\naddress, without their explicit permission\u003c/li\u003e\n\u003cli\u003eOther conduct which could reasonably be considered inappropriate in a\nprofessional setting\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id="enforcement-responsibilities"\u003eEnforcement Responsibilities\u003c/h2\u003e\n\u003cp\u003eCommunity leaders are responsible for clarifying and enforcing our standards of\nacceptable behavior and will take appropriate and fair corrective action in\nresponse to any behavior that they deem inappropriate, threatening, offensive,\nor harmful.\u003c/p\u003e\n\u003cp\u003eCommunity leaders have the right and responsibility to remove, edit, or reject\ncomments, commits, code, wiki edits, issues, and other contributions that are\nnot aligned to this Code of Conduct, and will communicate reasons for moderation\ndecisions when appropriate.\u003c/p\u003e\n\u003ch2 id="scope"\u003eScope\u003c/h2\u003e\n\u003cp\u003eThis Code of Conduct applies within all community spaces, and also applies when\nan individual is officially representing the community in public spaces.\nExamples of representing our community include using an official e-mail address,\nposting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event.\u003c/p\u003e\n\u003ch2 id="enforcement"\u003eEnforcement\u003c/h2\u003e\n\u003cp\u003eInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported to the community leaders responsible for enforcement at\n.\nAll complaints will be reviewed and investigated promptly and fairly.\u003c/p\u003e\n\u003cp\u003eAll community leaders are obligated to respect the privacy and security of the\nreporter of any incident.\u003c/p\u003e\n\u003ch2 id="enforcement-guidelines"\u003eEnforcement Guidelines\u003c/h2\u003e\n\u003cp\u003eCommunity leaders will follow these Community Impact Guidelines in determining\nthe consequences for any action they deem in violation of this Code of Conduct:\u003c/p\u003e\n\u003ch3 id="1-correction"\u003e1. Correction\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eCommunity Impact\u003c/strong\u003e: Use of inappropriate language or other behavior deemed\nunprofessional or unwelcome in the community.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eConsequence\u003c/strong\u003e: A private, written warning from community leaders, providing\nclarity around the nature of the violation and an explanation of why the\nbehavior was inappropriate. A public apology may be requested.\u003c/p\u003e\n\u003ch3 id="2-warning"\u003e2. Warning\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eCommunity Impact\u003c/strong\u003e: A violation through a single incident or series\nof actions.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eConsequence\u003c/strong\u003e: A warning with consequences for continued behavior. No\ninteraction with the people involved, including unsolicited interaction with\nthose enforcing the Code of Conduct, for a specified period of time. This\nincludes avoiding interactions in community spaces as well as external channels\nlike social media. Violating these terms may lead to a temporary or\npermanent ban.\u003c/p\u003e\n\u003ch3 id="3-temporary-ban"\u003e3. Temporary Ban\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eCommunity Impact\u003c/strong\u003e: A serious violation of community standards, including\nsustained inappropriate behavior.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eConsequence\u003c/strong\u003e: A temporary ban from any sort of interaction or public\ncommunication with the community for a specified period of time. No public or\nprivate interaction with the people involved, including unsolicited interaction\nwith those enforcing the Code of Conduct, is allowed during this period.\nViolating these terms may lead to a permanent ban.\u003c/p\u003e\n\u003ch3 id="4-permanent-ban"\u003e4. Permanent Ban\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eCommunity Impact\u003c/strong\u003e: Demonstrating a pattern of violation of community\nstandards, including sustained inappropriate behavior,  harassment of an\nindividual, or aggression toward or disparagement of classes of individuals.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eConsequence\u003c/strong\u003e: A permanent ban from any sort of public interaction within\nthe community.\u003c/p\u003e\n\u003ch2 id="attribution"\u003eAttribution\u003c/h2\u003e\n\u003cp\u003eThis Code of Conduct is adapted from the \u003ca href="https://www.contributor-covenant.org"\u003eContributor Covenant\u003c/a\u003e,\nversion 2.0, available at\nhttps://www.contributor-covenant.org/version/2/0/code_of_conduct.html.\u003c/p\u003e\n\u003cp\u003eCommunity Impact Guidelines were inspired by \u003ca href="https://github.com/mozilla/diversity"\u003eMozilla\u0026rsquo;s code of conduct\nenforcement ladder\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eFor answers to common questions about this code of conduct, see the FAQ at\nhttps://www.contributor-covenant.org/faq. Translations are available at\nhttps://www.contributor-covenant.org/translations.\u003c/p\u003e\n'},{id:12,href:"https://kubedl.io/docs/prologue/install-using-yaml/",title:"Install Using Yaml",description:"",content:'\u003ch2 id="install-crds"\u003eInstall CRDs\u003c/h2\u003e\n\u003cp\u003eFrom \u003ca href="https://github.com/alibaba/kubedl"\u003egit root directory\u003c/a\u003e, run\u003c/p\u003e\n\u003cdiv class="doks-clipboard"\u003e\n  \u003cbutton class="btn-clipboard btn btn-link" data-clipboard-text="kubectl apply -f helm/kubedl/crds/"\u003e\u003cspan class="copy-status"\u003e\u003c/span\u003e\u003c/button\u003e\n\u003c/div\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl apply -f helm/kubedl/crds/\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id="install-kubedl-controller"\u003eInstall KubeDL controller\u003c/h2\u003e\n\u003cp\u003eA single yaml file including everything: deployment, rbac etc.\u003c/p\u003e\n\u003cdiv class="doks-clipboard"\u003e\n  \u003cbutton class="btn-clipboard btn btn-link" data-clipboard-text="kubectl apply -f https://raw.githubusercontent.com/alibaba/kubedl/v0.3.0/config/manager/all_in_one.yaml"\u003e\u003cspan class="copy-status"\u003e\u003c/span\u003e\u003c/button\u003e\n\u003c/div\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl apply -f https://raw.githubusercontent.com/alibaba/kubedl/v0.3.0/config/manager/all_in_one.yaml\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eKubeDL controller is installed under \u003ccode\u003ekubedl-system\u003c/code\u003e namespace.\u003c/p\u003e\n\u003cp\u003eThe official KubeDL controller image is hosted under \u003ca href="https://hub.docker.com/r/kubedl/kubedl"\u003edocker hub\u003c/a\u003e.\u003c/p\u003e\n\u003ch2 id="uninstall-kubedl-controller"\u003eUninstall KubeDL controller\u003c/h2\u003e\n\u003cdiv class="doks-clipboard"\u003e\n  \u003cbutton class="btn-clipboard btn btn-link" data-clipboard-text="kubectl delete namespace kubedl-system"\u003e\u003cspan class="copy-status"\u003e\u003c/span\u003e\u003c/button\u003e\n\u003c/div\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl delete namespace kubedl-system\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id="delete-crds"\u003eDelete CRDs\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl delete crd elasticdljobs.training.kubedl.io marsjobs.training.kubedl.io mpijobs.training.kubedl.io pytorchjobs.training.kubedl.io tfjobs.training.kubedl.io xdljobs.training.kubedl.io xgboostjobs.training.kubedl.io\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id="enable-specific-job-kind"\u003eEnable specific job Kind\u003c/h2\u003e\n\u003cp\u003eKubeDL supports all kinds of jobs(tensorflow, pytorch etc.) in a single Kubernetes operator. You can selectively enable the kind of jobs to support.\nThere are three options:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eDefault option. Just install the job CRDs required. KubeDL will automatically enable the corresponding job controller.\u003c/li\u003e\n\u003cli\u003eSet env \u003ccode\u003eWORKLOADS_ENABLE\u003c/code\u003e in KubeDL container. The value is a list of job types to be enabled. For example, \u003ccode\u003eWORKLOADS_ENABLE=TFJob,PytorchJob\u003c/code\u003e means only Tensorflow and Pytorch Job are enabled.\u003c/li\u003e\n\u003cli\u003eSet startup flags \u003ccode\u003e--workloads\u003c/code\u003e in KubeDL container command args. The value is a list of job types to be enabled like \u003ccode\u003e--workloads TFJob,PytorchJob\u003c/code\u003e.\u003c/li\u003e\n\u003c/ol\u003e\n'},{id:13,href:"https://kubedl.io/docs/workloads/mars/",title:"Mars",description:"Running mars on Kubernetes",content:'\u003ch2 id="whats-mars"\u003eWhat\u0026rsquo;s Mars\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eMars\u003c/code\u003e is a tensor-based unified framework for large-scale data computation which scales Numpy, Pandas and Scikit-learn,\nsee \u003ca href="https://github.com/mars-project/mars"\u003emars-repo\u003c/a\u003e for details. As a data computation framework, \u003ccode\u003emars\u003c/code\u003e is easy to\nscale out and can run across hundreds of machines simultaneously to accelerate large scale data tasks.\u003cbr\u003e\u003c/p\u003e\n\u003cp\u003eA distributed mars job includes 3 roles to collaborate with each other：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eWebService\u003c/strong\u003e: web-service accepts requests from end-users and forwards the whole tensor-graph to scheduler, it provides a dashboard for end users to track job status and submit tasks interactively.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eScheduler\u003c/strong\u003e: scheduler compiles and holds a global view of tensor-graph, it schedules \u0026lsquo;operands\u0026rsquo; and \u0026lsquo;chunks\u0026rsquo; to workers.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWorker\u003c/strong\u003e:  worker listen to \u0026lsquo;operands\u0026rsquo; and \u0026lsquo;chunks\u0026rsquo; dispatched by scheduler, executes the tasks, and reports results back to scheduler.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id="run-mars-with-kubedl"\u003eRun Mars with KubeDL\u003c/h2\u003e\n\u003cp\u003eRun \u003ccode\u003emars\u003c/code\u003e job on kubernetes natively.\u003c/p\u003e\n\u003ch3 id="1-deploy-kubedl"\u003e1. Deploy KubeDL\u003c/h3\u003e\n\u003cp\u003eFollow the \u003ca href="https://kubedl.io/docs/prologue/introduction/"\u003einstallation tutorial\u003c/a\u003e.\u003c/p\u003e\n\u003ch3 id="2-apply-mars-crd"\u003e2. Apply Mars CRD\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eMars\u003c/code\u003e CRD(CustomResourceDefinition) manifest file describes the structure of a mars job spec. Run the following to apply the CRD:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl apply -f https://raw.githubusercontent.com/alibaba/kubedl/v0.3.0/config/crd/bases/training.kubedl.io_marsjobs.yaml\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id="3-create-a-mars-job"\u003e3. Create a Mars Job\u003c/h3\u003e\n\u003cp\u003eCreate a YAML spec that describes the requirements of a MarsJob such as the worker, scheduler, WebService like below\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-yaml"\u003eapiVersion: training.kubedl.io/v1alpha1\nkind: MarsJob\nmetadata:\n  name: mars-test-demo\n  namespace: default\nspec:\n  cleanPodPolicy: None\n  webHost: mars.domain.com\n  marsReplicaSpecs:\n    Scheduler:\n      replicas: 1\n      restartPolicy: Never\n      template:\n        metadata:\n          labels:\n            mars/service-type: marsscheduler\n        spec:\n          containers:\n            - command:\n                - /bin/sh\n                - -c\n                - python -m mars.deploy.kubernetes.scheduler\n              image: mars-image\n              imagePullPolicy: Always\n              name: mars\n              resources:\n                limits:\n                  cpu: 2\n                  memory: 2Gi\n                requests:\n                  cpu: 2\n                  memory: 2Gi\n          serviceAccountName: kubedl-sa\n    WebService:\n      replicas: 1\n      restartPolicy: Never\n      template:\n        metadata:\n          labels:\n            mars/service-type: marswebservice\n        spec:\n          containers:\n            - command:\n                - /bin/sh\n                - -c\n                - python -m mars.deploy.kubernetes.web\n              image: mars-image\n              imagePullPolicy: Always\n              name: mars\n              resources:\n                limits:\n                  cpu: 2\n                  memory: 2Gi\n                requests:\n                  cpu: 2\n                  memory: 2Gi\n          serviceAccountName: kubedl-sa\n    Worker:\n      replicas: 2\n      restartPolicy: Never\n      template:\n        metadata:\n          labels:\n            mars/service-type: marsworker\n        spec:\n          containers:\n            - command:\n                - /bin/sh\n                - -c\n                - python -m mars.deploy.kubernetes.worker\n              image: mars-image\n              imagePullPolicy: Always\n              name: mars\n              resources:\n                limits:\n                  cpu: 2\n                  memory: 2Gi\n                requests:\n                  cpu: 2\n                  memory: 2Gi\n          serviceAccountName: kubedl-sa\nstatus: {}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe \u003ccode\u003espec\u003c/code\u003e field describes the requirement of each replica, including \u003ccode\u003ereplicas\u003c/code\u003e, \u003ccode\u003erestartPolicy\u003c/code\u003e, \u003ccode\u003etemplate\u003c/code\u003e\u0026hellip;and\nthe \u003ccode\u003estatus\u003c/code\u003e field describes the job current status. Run following command to start an example mars job:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl create -f example/mars/mars-test-demo.yaml\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eCheck the mars job status:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003e$ kubectl get marsjob\nNAME             STATE     AGE   FINISHED-TTL   MAX-LIFETIME\nmars-test-demo   Running   40m\n$ kubectl get pods\nNAME                                            READY   STATUS             RESTARTS   AGE\nmars-test-demo-scheduler-0                      1/1     Running            0          40m\nmars-test-demo-webservice-0                     1/1     Running            0          40m\nmars-test-demo-worker-0                         1/1     Running            0          40m\nmars-test-demo-worker-1                         1/1     Running            0          40m\n\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id="4-access-web-service"\u003e4. Access web-service.\u003c/h3\u003e\n\u003cfigure\u003e\n  \u003cimg class="img-fluid lazyload blur-up" data-sizes="auto" src="https://kubedl.io/docs/workloads/mars/mars-ingress_hu3d024fe99bd4d562ba755cd6f9fa87db_47305_20x0_resize_box_2.png" data-srcset="https://kubedl.io/docs/workloads/mars/mars-ingress_hu3d024fe99bd4d562ba755cd6f9fa87db_47305_900x0_resize_box_2.png 900w,https://kubedl.io/docs/workloads/mars/mars-ingress_hu3d024fe99bd4d562ba755cd6f9fa87db_47305_800x0_resize_box_2.png 800w,https://kubedl.io/docs/workloads/mars/mars-ingress_hu3d024fe99bd4d562ba755cd6f9fa87db_47305_700x0_resize_box_2.png 700w,https://kubedl.io/docs/workloads/mars/mars-ingress_hu3d024fe99bd4d562ba755cd6f9fa87db_47305_600x0_resize_box_2.png 600w,https://kubedl.io/docs/workloads/mars/mars-ingress_hu3d024fe99bd4d562ba755cd6f9fa87db_47305_500x0_resize_box_2.png 500w" width="892" height="452" alt="mars-ingress"\u003e\n  \u003cnoscript\u003e\u003cimg class="img-fluid" sizes="100vw" srcset="https://kubedl.io/docs/workloads/mars/mars-ingress_hu3d024fe99bd4d562ba755cd6f9fa87db_47305_900x0_resize_box_2.png 900w,https://kubedl.io/docs/workloads/mars/mars-ingress_hu3d024fe99bd4d562ba755cd6f9fa87db_47305_800x0_resize_box_2.png 800w,https://kubedl.io/docs/workloads/mars/mars-ingress_hu3d024fe99bd4d562ba755cd6f9fa87db_47305_700x0_resize_box_2.png 700w,https://kubedl.io/docs/workloads/mars/mars-ingress_hu3d024fe99bd4d562ba755cd6f9fa87db_47305_600x0_resize_box_2.png 600w,https://kubedl.io/docs/workloads/mars/mars-ingress_hu3d024fe99bd4d562ba755cd6f9fa87db_47305_500x0_resize_box_2.png 500w" src="https://kubedl.io/docs/workloads/mars/mars-ingress.png" width="892" height="452" alt="mars-ingress"\u003e\u003c/noscript\u003e\n  \u003cfigcaption class="figure-caption"\u003emars-ingress\u003c/figcaption\u003e\n\u003c/figure\u003e\n\n\u003cp\u003eWeb service visualizes job status, computation process progress and provides an entry for interactive submission.\nHowever, web service instance was running as a pod inside a kubernetes cluster which may not be accessible by external users.\n\u003ccode\u003eKubeDL\u003c/code\u003e provides two access modes for users in different network environment.\u003c/p\u003e\n\u003ch4 id="41-access-web-service-in-cluster"\u003e4.1 Access web-service in-cluster.\u003c/h4\u003e\n\u003cp\u003eFor users in the same network environment with web service instance, they can directly access its \u003cem\u003eservice\u003c/em\u003e without any other additional configurations,\nand the address is formatted as: \u003ccode\u003e{webservice-name}.{namespace}\u003c/code\u003e, it is a \u003ccode\u003eA\u003c/code\u003e record generated by \u003ccode\u003eCoreDNS\u003c/code\u003e, so you have to ensure that \u003ccode\u003eCoreDNS\u003c/code\u003e has been\ndeployed.\u003c/p\u003e\n\u003ch4 id="42-access-web-service-outside-cluster"\u003e4.2 Access web-service outside cluster.\u003c/h4\u003e\n\u003cp\u003eFor users in different network environment(e.g. an internet user wants to access a mars web-service running in vpc),\nusers have to apply an SLB address first, so that they can ping the ip in \u003cstrong\u003evpc\u003c/strong\u003e with a public address by SLB domain resolving, then in job spec, users just need fill the \u003ccode\u003espec.webHost\u003c/code\u003e field with\ntheir applied SLB address, \u003ccode\u003eKubeDL\u003c/code\u003ewill generated ingress instance with routing rules, so that external traffic can be routed to target web service and that\nbecomes available for outside users.\u003c/p\u003e\n\u003ch3 id="5-memory-tuning-policy"\u003e5. Memory Tuning Policy\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eWorker\u003c/code\u003e is the role that actually performs computing tasks in \u003ccode\u003eMarsJob\u003c/code\u003e.\nMars supports running jobs in different memory usage scenarios. For example, swap cold in-memory data out to spill dirs and persist in kubernetes ephemeral-storage.\n\u003ccode\u003eMars\u003c/code\u003e provides plentiful memory tuning options which has been integrated to \u003ccode\u003eMarsJob\u003c/code\u003e type definition, including :\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eplasmaStore: PlasmaStore specify the socket path of plasma store that handles shared memory between all worker processes.\u003c/li\u003e\n\u003cli\u003elockFreeFileIO: LockFreeFileIO indicates whether spill dirs are dedicated or not.\u003c/li\u003e\n\u003cli\u003espillDirs: SpillDirs specify multiple directory paths, when size of in-memory objects is about to reach the limitation, mars workers will swap cold data out to spill dirs and persist in ephemeral-storage.\u003c/li\u003e\n\u003cli\u003eworkerCachePercentage: WorkerCachePercentage specify the percentage of total available memory size can be used as cache, it will be overridden by workerCacheSize if it is been set.\u003c/li\u003e\n\u003cli\u003eworkerCacheSize：WorkerCacheSize specify the exact cache quantity can be used.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eusers can set above options in \u003ccode\u003ejob.spec.memoryTuningPolicy\u003c/code\u003e field:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-yaml"\u003eapiVersion: training.kubedl.io/v1alpha1\nkind: MarsJob\nmetadata:\n  name: mars-test-demo\n  namespace: default\nspec:\n  cleanPodPolicy: None\n  memoryTuningPolicy:\n    plasmaStore: string              # /etc/pstore/...\n    lockFreeFileIO: bool             # false\n    spillDirs: []string              # ...\n    workerCachePercentage: int32     # 80, indicates 80%\n    workerCacheSize: quantity        # 10Gi\n  marsReplicaSpecs:\n    ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id="run-mars-in-standalone-mode"\u003eRun Mars in Standalone Mode\u003c/h2\u003e\n\u003cp\u003eIn standalone mode, a distributed \u003ccode\u003eMars\u003c/code\u003e job are running standalone on bare hosts without the help of other container orchestration tools.\nBut this requires manual configuration effort and lack other abilities such as automatic failover of workers.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003erun \u003ccode\u003epip install pymars[distributed]\u003c/code\u003e on every node in the cluster to install dependencies needed for distributed execution.\u003c/li\u003e\n\u003cli\u003estart different mars role processes on each node.\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003emars-scheduler -a \u0026lt;scheduler_ip\u0026gt; -p \u0026lt;scheduler_port\u0026gt;\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003emars-web -a \u0026lt;web_ip\u0026gt; -p \u0026lt;web_port\u0026gt; -s \u0026lt;scheduler_ip\u0026gt;:\u0026lt;scheduler_port\u0026gt;\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003emars-worker -a \u0026lt;worker_ip\u0026gt; -p \u0026lt;worker_port\u0026gt; -s \u0026lt;scheduler_ip\u0026gt;:\u0026lt;scheduler_port\u0026gt;\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eusually there must be at least 1 web-service and 1 scheduler and a certain number of workers.\u003c/li\u003e\n\u003cli\u003eafter all processes started, users can open the python console run snippet to create a session with web-service and submit tasks.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode class="language-python"\u003eimport mars.tensor as mt\nimport mars.dataframe as md\nfrom mars.session import new_session\nnew_session(\'http://\u0026lt;web_ip\u0026gt;:\u0026lt;web_port\u0026gt;\').as_default()\na = mt.ones((2000, 2000), chunk_size=200)\nb = mt.inner(a, a)\nb.execute()  # submit tensor to cluster\ndf = md.DataFrame(a).sum()\ndf.execute()  # submit DataFrame to cluster\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id="spec"\u003eSpec\u003c/h2\u003e\n\u003cp\u003eCheck the CRD definition. \u003ca href="https://github.com/alibaba/kubedl/blob/master/apis/training/v1alpha1/marsjob_types.go"\u003eGo -\u0026gt;\u003c/a\u003e\u003c/p\u003e\n'},{id:14,href:"https://kubedl.io/docs/recipes/",title:"Recipes",description:"Recipes",content:""},{id:15,href:"https://kubedl.io/docs/help/dingtalk/",title:"Dingtalk",description:"Dingtalk Help.",content:'\u003cp\u003eGet help on joining the Dingtalk(钉钉) Group\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class="img-fluid lazyload blur-up" data-sizes="auto" src="https://kubedl.io/docs/help/dingtalk/kubedl_hu0d572a5a19c12dcb10b88d4fb51252c9_212191_20x0_resize_box_2.png" data-srcset="https://kubedl.io/docs/help/dingtalk/kubedl_hu0d572a5a19c12dcb10b88d4fb51252c9_212191_800x0_resize_box_2.png 800w,https://kubedl.io/docs/help/dingtalk/kubedl_hu0d572a5a19c12dcb10b88d4fb51252c9_212191_700x0_resize_box_2.png 700w,https://kubedl.io/docs/help/dingtalk/kubedl_hu0d572a5a19c12dcb10b88d4fb51252c9_212191_600x0_resize_box_2.png 600w,https://kubedl.io/docs/help/dingtalk/kubedl_hu0d572a5a19c12dcb10b88d4fb51252c9_212191_500x0_resize_box_2.png 500w" width="828" height="1068" alt="Dingtalk"\u003e\n  \u003cnoscript\u003e\u003cimg class="img-fluid" sizes="100vw" srcset="https://kubedl.io/docs/help/dingtalk/kubedl_hu0d572a5a19c12dcb10b88d4fb51252c9_212191_800x0_resize_box_2.png 800w,https://kubedl.io/docs/help/dingtalk/kubedl_hu0d572a5a19c12dcb10b88d4fb51252c9_212191_700x0_resize_box_2.png 700w,https://kubedl.io/docs/help/dingtalk/kubedl_hu0d572a5a19c12dcb10b88d4fb51252c9_212191_600x0_resize_box_2.png 600w,https://kubedl.io/docs/help/dingtalk/kubedl_hu0d572a5a19c12dcb10b88d4fb51252c9_212191_500x0_resize_box_2.png 500w" src="https://kubedl.io/docs/help/dingtalk/kubedl.png" width="828" height="1068" alt="Dingtalk"\u003e\u003c/noscript\u003e\n  \u003cfigcaption class="figure-caption"\u003eDingtalk\u003c/figcaption\u003e\n\u003c/figure\u003e\n\n'},{id:16,href:"https://kubedl.io/docs/recipes/tensorboard/",title:"Tensorboard",description:"",content:'\u003cp\u003eKubeDL can attach a tensorboard to a running tensorflow job.\nUsers can visualize the tensorflow job with the tensorboard.\u003c/p\u003e\n\u003cp\u003eTo use tensorboard, users must ensure that the tensorflow job logs are created and stored in a kubernetes remote volume (emptyDir, hostPath and local volume are not supported) and the tensorboard pod can mount the volume.\u003c/p\u003e\n\u003cp\u003eUsers can set the tensorboard config in the job\u0026rsquo;s annotation with key \u003ccode\u003ekubedl.io/tensorboard-config\u003c/code\u003e as below.\nAfter that, users can access the tensorboard through this URL \u003ccode\u003ehttp://\u0026lt;ingress host\u0026gt;/\u0026lt;ingress pathPrefix\u0026gt;/\u0026lt;job namespace\u0026gt;/\u0026lt;job name\u0026gt;\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eFor example:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-yaml"\u003e    apiVersion: \u0026quot;training.kubedl.io/v1alpha1\u0026quot;\n    kind: \u0026quot;TFJob\u0026quot;\n    metadata:\n      name: \u0026quot;mnist\u0026quot;\n      namespace: kubedl\n      annotations:\n +      kubedl.io/tensorboard-config: \'{\u0026quot;logDir\u0026quot;:\u0026quot;/var/log/training\u0026quot;,\u0026quot;ttlSecondsAfterJobFinished\u0026quot;:3600,\u0026quot;ingressSpec\u0026quot;:{\u0026quot;host\u0026quot;:\u0026quot;locahost\u0026quot;,\u0026quot;pathPrefix\u0026quot;:\u0026quot;/tb\u0026quot;}}\'\n    spec:\n      cleanPodPolicy: None\n      tfReplicaSpecs:\n        ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eA full list of supported options are:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-json5"\u003e{\n    \u0026quot;logDir\u0026quot;: \u0026quot;xxx\u0026quot;,            // the path of the tensorflow job logs (required).\n    \u0026quot;ttlSecondsAfterJobFinished\u0026quot;: 3600,     // the TTL to clean up the tensorboard after the job is finished (required).\n    \u0026quot;image\u0026quot;: \u0026quot;xxx\u0026quot;,             // the image of the tensorboard, default value is the job\'s image (optional).\n    \u0026quot;ingressSpec\u0026quot;: {            // the ingress of the tensorboard (required).\n        \u0026quot;host\u0026quot;: \u0026quot;xxx\u0026quot;,          // the ingress host (required).\n        \u0026quot;pathPrefix\u0026quot;: \u0026quot;xxx\u0026quot;,    // the pathPrefix will be set to the ingress path with the pattern: \u0026lt;pathPrefix\u0026gt;/\u0026lt;job namespace\u0026gt;/\u0026lt;job name\u0026gt; (required).\n        \u0026quot;annotations\u0026quot;: {        // the annotations of the ingress (optional).\n            \u0026quot;xxx\u0026quot;: \u0026quot;xxx\u0026quot;\n        }\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n'},{id:17,href:"https://kubedl.io/docs/prologue/quick-start/",title:"Quick Start",description:"Run a simple MNist Tensorflow job with KubeDL.",content:'\u003ch2 id="submit-the-tensorflow-job"\u003eSubmit the TensorFlow job\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl apply -f https://raw.githubusercontent.com/alibaba/kubedl/v0.3.0/example/tf/tf_job_mnist.yaml\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id="get-job-status"\u003eGet job status\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl get tfjobs -n kubedl\nkubectl describe tfjob mnist -n kubedl\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id="delete-the-job"\u003eDelete the job\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl delete tfjob mnist -n kubedl\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id="other-commands"\u003eOther commands\u003c/h2\u003e\n\u003cp\u003e\u003ca href="https://kubedl.io/docs/prologue/commands/"\u003eCommands →\u003c/a\u003e\u003c/p\u003e\n'},{id:18,href:"https://kubedl.io/docs/references/",title:"References",description:"References",content:""},{id:19,href:"https://kubedl.io/docs/contributing/",title:"Contributing",description:"Contributing",content:""},{id:20,href:"https://kubedl.io/docs/recipes/metadata-persistentcy/",title:"Metadata Persistency",description:"",content:'\u003cp\u003eKubernetes api-server typically stores job information for a limited lifespan. KubeDL has built-in support to persist the\njob metadata into external storage to outlive api-server state.\nThe KubeDL controller will persist the job metadata during the lifecycle of job such as job and pod creation/deletion.\u003c/p\u003e\n\u003cp\u003eCurrently, only \u003ccode\u003eMysql\u003c/code\u003e is supported.\u003c/p\u003e\n\u003ch2 id="db-schema"\u003eDB Schema\u003c/h2\u003e\n\u003ch3 id="job-table"\u003eJob Table\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003cstrong\u003eColumn\u003c/strong\u003e\u003c/th\u003e\n\u003cth\u003e\u003cstrong\u003eType\u003c/strong\u003e\u003c/th\u003e\n\u003cth\u003e\u003cstrong\u003eDescription\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eid\u003c/td\u003e\n\u003ctd\u003eint(64)\u003c/td\u003e\n\u003ctd\u003eprimary id auto incremented by underlying database\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ename\u003c/td\u003e\n\u003ctd\u003evarchar(128)\u003c/td\u003e\n\u003ctd\u003ename of job\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003enamespace\u003c/td\u003e\n\u003ctd\u003evarchar(128)\u003c/td\u003e\n\u003ctd\u003enamespace of job\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ejob_id\u003c/td\u003e\n\u003ctd\u003evarchar(64)\u003c/td\u003e\n\u003ctd\u003ejob uid generated by kubernetes\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eversion\u003c/td\u003e\n\u003ctd\u003evarchar(32)\u003c/td\u003e\n\u003ctd\u003eresource version generated by kubernetes(etcd)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003estatus\u003c/td\u003e\n\u003ctd\u003evarchar(32)\u003c/td\u003e\n\u003ctd\u003ecurrent observed job status(Created/Running/Failed/Succeed/Restarting)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ekind\u003c/td\u003e\n\u003ctd\u003evarchar(32)\u003c/td\u003e\n\u003ctd\u003ekind of job: TFJob,PyTorchJob\u0026hellip;\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eresources\u003c/td\u003e\n\u003ctd\u003etext\u003c/td\u003e\n\u003ctd\u003ejob requested resources, including replicas and resources of each role.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003edeploy_region\u003c/td\u003e\n\u003ctd\u003evarchar(64)\u003c/td\u003e\n\u003ctd\u003edeploy_region indicates the physical region(IDC) this job located in, reserved for jobs running in across-region-clusters\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003etenant\u003c/td\u003e\n\u003ctd\u003evarchar(255)\u003c/td\u003e\n\u003ctd\u003efields reserved for multi-tenancy job management scenarios, indicating which tenant this job belongs to and who\u0026rsquo;s the owner(user)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eowner\u003c/td\u003e\n\u003ctd\u003evarchar(255)\u003c/td\u003e\n\u003ctd\u003eowner of job\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eis_in_etcd\u003c/td\u003e\n\u003ctd\u003etinyint(4)\u003c/td\u003e\n\u003ctd\u003eis_in_etcd indicates that whether record of this job has been removed from etcd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003egmt_created\u003c/td\u003e\n\u003ctd\u003edatetime\u003c/td\u003e\n\u003ctd\u003etimestamp when job created\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003egmt_modified\u003c/td\u003e\n\u003ctd\u003edatetime\u003c/td\u003e\n\u003ctd\u003etimestamp when last job status transited\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003egmt_finished\u003c/td\u003e\n\u003ctd\u003edatetime\u003c/td\u003e\n\u003ctd\u003etimestamp when job failed or succeed\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id="pod-table"\u003ePod Table\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003cstrong\u003eColumn\u003c/strong\u003e\u003c/th\u003e\n\u003cth\u003e\u003cstrong\u003eType\u003c/strong\u003e\u003c/th\u003e\n\u003cth\u003e\u003cstrong\u003eDescription\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eid\u003c/td\u003e\n\u003ctd\u003eint(64)\u003c/td\u003e\n\u003ctd\u003eprimary id auto incremented by underlying database\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ename\u003c/td\u003e\n\u003ctd\u003evarchar(128)\u003c/td\u003e\n\u003ctd\u003ename of pod\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003enamespace\u003c/td\u003e\n\u003ctd\u003evarchar(128)\u003c/td\u003e\n\u003ctd\u003enamespace of pod\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003epod_id\u003c/td\u003e\n\u003ctd\u003evarchar(64)\u003c/td\u003e\n\u003ctd\u003epod uid generated by kubernetes\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eversion\u003c/td\u003e\n\u003ctd\u003evarchar(32)\u003c/td\u003e\n\u003ctd\u003eresource version generated by kubernetes(etcd)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003estatus\u003c/td\u003e\n\u003ctd\u003evarchar(32)\u003c/td\u003e\n\u003ctd\u003ecurrent observed pod phase(Pending/Running/Failed/Succeed/Unkown)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eimage\u003c/td\u003e\n\u003ctd\u003evarchar(255)\u003c/td\u003e\n\u003ctd\u003eimage name of main conatiner\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ejob_id\u003c/td\u003e\n\u003ctd\u003evarchar(64)\u003c/td\u003e\n\u003ctd\u003ejob id of this pod controlled by\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ereplica_type\u003c/td\u003e\n\u003ctd\u003evarchar(32)\u003c/td\u003e\n\u003ctd\u003ereplica type of this pod belongs to\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eresources\u003c/td\u003e\n\u003ctd\u003evarchar(1024)\u003c/td\u003e\n\u003ctd\u003eresources this pod requested, marshaled from a ResourceRequirements object\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ehost_ip\u003c/td\u003e\n\u003ctd\u003evarchar(64)\u003c/td\u003e\n\u003ctd\u003eip of the host this pod scheduled\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003epod_ip\u003c/td\u003e\n\u003ctd\u003evarchar(64)\u003c/td\u003e\n\u003ctd\u003eip of this pod allocated\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003edeploy_region\u003c/td\u003e\n\u003ctd\u003evarchar(64)\u003c/td\u003e\n\u003ctd\u003edeploy_region indicates the physical region(IDC) this job located in\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eis_in_etcd\u003c/td\u003e\n\u003ctd\u003etinyint(4)\u003c/td\u003e\n\u003ctd\u003eis_in_etcd indicates that whether record of this job has been removed from etcd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eremark\u003c/td\u003e\n\u003ctd\u003etext\u003c/td\u003e\n\u003ctd\u003eextended messaged for pod\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003egmt_created\u003c/td\u003e\n\u003ctd\u003edatetime\u003c/td\u003e\n\u003ctd\u003etimestamp when pod created\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003egmt_modified\u003c/td\u003e\n\u003ctd\u003edatetime\u003c/td\u003e\n\u003ctd\u003etimestamp when last pod status transited\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003egmt_started\u003c/td\u003e\n\u003ctd\u003edatetime\u003c/td\u003e\n\u003ctd\u003etimestamp when main container stared\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003egmt_finished\u003c/td\u003e\n\u003ctd\u003edatetime\u003c/td\u003e\n\u003ctd\u003etimestamp when pod failed or succeed\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id="how-to-use"\u003eHow To Use\u003c/h2\u003e\n\u003cp\u003eBelow is an example to setup KubeDL to use \u003ccode\u003eMysql\u003c/code\u003e as the persistency DB.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eSet up credentials for KubeDL to connect to DB. Create a \u003ccode\u003eSecret\u003c/code\u003e object like below:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode class="language-yaml"\u003eapiVersion: v1\nkind: Secret\nmetadata:\n  name: kubedl-mysql-config\n  namespace: kubedl-system\ntype: Opaque\nstringData:\n  host: my.host.com\n  dbName: kubedl\n  user: kubedl-user\n  password: this-is-me\n  port: \u0026quot;3306\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003col start="2"\u003e\n\u003cli\u003eUpdate the Kubedl Deployment spec to include \u003ccode\u003e--meta-storage mysql\u003c/code\u003e in the startup flag and reference the DB credentials\nvia environment variables. The KubeDL controller uses the env to set up connection with DB.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode class="language-yaml"\u003eapiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kubedl\n  namespace: kubedl-system\n  labels:\n    app: kubedl\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: kubedl\n  template:\n    metadata:\n      labels:\n        app: kubedl\n    spec:\n      containers:\n      - image: kubedl/kubedl:v0.3.0\n        imagePullPolicy: Always\n        name: kubedl-manager\n        args:\n        - \u0026quot;--meta-storage\u0026quot;\n        - \u0026quot;mysql\u0026quot;\n        env:\n        - name: MYSQL_HOST\n          value:\n          valueFrom:\n            secretKeyRef:\n              name: kubedl-mysql-config\n              key: host\n        - name: MYSQL_DB_NAME\n          value:\n          valueFrom:\n            secretKeyRef:\n              name: kubedl-mysql-config\n              key: dbName\n        - name: MYSQL_USER\n          value:\n          valueFrom:\n            secretKeyRef:\n              name: kubedl-mysql-config\n              key: user\n        - name: MYSQL_PASSWORD\n          value:\n          valueFrom:\n            secretKeyRef:\n              name: kubedl-mysql-config\n              key: password\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id="mysql-config"\u003eMySql Config\u003c/h2\u003e\n\u003cp\u003eThe configs defined in the aforementioned \u003ccode\u003esecret\u003c/code\u003e:\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eConfig Name\u003c/th\u003e\n\u003cth\u003eDescription\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003ehost\u003c/td\u003e\n\u003ctd\u003eMysql host name\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003edbName\u003c/td\u003e\n\u003ctd\u003eDB name\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003euser\u003c/td\u003e\n\u003ctd\u003eUser name\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003epassword\u003c/td\u003e\n\u003ctd\u003eUser password\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eport\u003c/td\u003e\n\u003ctd\u003eThe mysql DB port to connect to\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id="contributions"\u003eContributions\u003c/h2\u003e\n\u003cp\u003eCurrently, only \u003ccode\u003emysql\u003c/code\u003e is supported. You are welcome to contribute your own storage plugin.\u003c/p\u003e\n'},{id:21,href:"https://kubedl.io/docs/workloads/xgboost/",title:"XGBoost",description:"Run XGBoost on Kubernetes.",content:'\u003ch2 id="example"\u003eExample\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class="language-yaml"\u003eapiVersion: training.kubedl.io/v1alpha1\nkind: \u0026quot;XGBoostJob\u0026quot;\nmetadata:\n  name: \u0026quot;xgboost-dist-iris-test-train\u0026quot;\nspec:\n  xgbReplicaSpecs:\n    Master:\n      replicas: 1\n      restartPolicy: Never\n      template:\n        apiVersion: v1\n        kind: Pod\n        spec:\n          containers:\n            - name: xgboostjob\n              image: docker.io/merlintang/xgboost-dist-iris:1.1\n              ports:\n                - containerPort: 9991\n                  name: xgboostjob-port\n              imagePullPolicy: Always\n              args:\n                - --job_type=Train\n                - --xgboost_parameter=objective:multi:softprob,num_class:3\n                - --n_estimators=10\n                - --learning_rate=0.1\n                - --model_path=autoAI/xgb-opt/2\n                - --model_storage_type=oss\n                - --oss_param=unknown\n    Worker:\n      replicas: 2\n      restartPolicy: ExitCode\n      template:\n        apiVersion: v1\n        kind: Pod\n        spec:\n          containers:\n            - name: xgboostjob\n              image: docker.io/merlintang/xgboost-dist-iris:1.1\n              ports:\n                - containerPort: 9991\n                  name: xgboostjob-port\n              imagePullPolicy: Always\n              args:\n                - --job_type=Train\n                - --xgboost_parameter=\u0026quot;objective:multi:softprob,num_class:3\u0026quot;\n                - --n_estimators=10\n                - --learning_rate=0.1\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id="spec"\u003eSpec\u003c/h2\u003e\n\u003cp\u003eCheck the CRD definition. \u003ca href="https://github.com/alibaba/kubedl/blob/master/apis/training/v1alpha1/xgboostjob_types.go"\u003eGo -\u0026gt;\u003c/a\u003e\u003c/p\u003e\n'},{id:22,href:"https://kubedl.io/docs/prologue/commands/",title:"Commands",description:"Commands for jobs",content:'\u003ch3 id="job-kind"\u003eJob kind\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003etfjob\u003c/li\u003e\n\u003cli\u003epytorchjob\u003c/li\u003e\n\u003cli\u003emarsjob\u003c/li\u003e\n\u003cli\u003empijob\u003c/li\u003e\n\u003cli\u003exdljob\u003c/li\u003e\n\u003cli\u003eelasticdljob\u003c/li\u003e\n\u003cli\u003exgboostjob\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThese kinds can be used in the kubectl command.\u003c/p\u003e\n\u003ch3 id="submit"\u003eSubmit\u003c/h3\u003e\n\u003cdiv class="doks-clipboard"\u003e\n  \u003cbutton class="btn-clipboard btn btn-link" data-clipboard-text="kubectl apply -f https://raw.githubusercontent.com/alibaba/kubedl/v0.3.0/example/tf/tf_job_mnist.yaml"\u003e\u003cspan class="copy-status"\u003e\u003c/span\u003e\u003c/button\u003e\n\u003c/div\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl apply -f https://raw.githubusercontent.com/alibaba/kubedl/v0.3.0/example/tf/tf_job_mnist.yaml\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id="list"\u003eList\u003c/h3\u003e\n\u003cdiv class="doks-clipboard"\u003e\n  \u003cbutton class="btn-clipboard btn btn-link" data-clipboard-text="kubectl get tfjobs -n kubedl"\u003e\u003cspan class="copy-status"\u003e\u003c/span\u003e\u003c/button\u003e\n\u003c/div\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl get tfjobs -n kubedl\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id="get"\u003eGet\u003c/h3\u003e\n\u003cdiv class="doks-clipboard"\u003e\n  \u003cbutton class="btn-clipboard btn btn-link" data-clipboard-text="kubectl describe tfjob mnist -n kubedl"\u003e\u003cspan class="copy-status"\u003e\u003c/span\u003e\u003c/button\u003e\n\u003c/div\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl describe tfjob mnist -n kubedl\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id="delete"\u003eDelete\u003c/h3\u003e\n\u003cdiv class="doks-clipboard"\u003e\n  \u003cbutton class="btn-clipboard btn btn-link" data-clipboard-text="kubectl delete tfjob mnist -n kubedl"\u003e\u003cspan class="copy-status"\u003e\u003c/span\u003e\u003c/button\u003e\n\u003c/div\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl delete tfjob mnist -n kubedl\n\u003c/code\u003e\u003c/pre\u003e\n'},{id:23,href:"https://kubedl.io/docs/recipes/events-persistentcy/",title:"Events Persistency",description:"",content:'\u003cp\u003eKubernetes object events are persisted for only 3 hours by default.\nIn addition to job meta persistency, KubeDL also supports persisting Kubernetes events into external storage system (usually time-series databases) to outlive api-server state.\nCurrently, KubeDL watches all Kubernetes events and persist them into external storage.\u003c/p\u003e\n\u003cp\u003eCurrently, only \u003ccode\u003ealiyun-sls\u003c/code\u003e is supported.\u003c/p\u003e\n\u003ch2 id="how-to-use"\u003eHow To Use\u003c/h2\u003e\n\u003cp\u003eBelow is an example for seting up KubeDL to persist events into \u003ca href="https://cn.aliyun.com/product/sls"\u003ealicloud simple log service\u003c/a\u003e.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eSet up credentials. Create a Secret:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode class="language-yaml"\u003eapiVersion: v1\nkind: Secret\nmetadata:\n  name: kubedl-sls-config\n  namespace: kubedl-system\ntype: Opaque\nstringData:\n  endpoint: zhangbei.log.aliyuncs.com\n  accessKey: my-ak\n  accessSecret: my-sk\n  project: kubedl-project\n  logStore: kubedl\n\u003c/code\u003e\u003c/pre\u003e\n\u003col start="2"\u003e\n\u003cli\u003eUpdate the KubeDL Deployment spec to include \u003ccode\u003e--event-storage aliyun-sls\u003c/code\u003e in the startup flag and reference the credentials\nvia environment variables.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode class="language-yaml"\u003eapiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kubedl\n  namespace: kubedl-system\n  labels:\n    app: kubedl\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: kubedl\n  template:\n    metadata:\n      labels:\n        app: kubedl\n    spec:\n      containers:\n      - image: kubedl/kubedl:v0.3.0\n        imagePullPolicy: Always\n        name: kubedl-manager\n        args:\n        - \u0026quot;--event-storage\u0026quot;\n        - \u0026quot;aliyun-sls\u0026quot;\n        env:\n        - name: SLS_ENDPOINT\n          value:\n          valueFrom:\n            secretKeyRef:\n              name: kubedl-sls-config\n              key: endpoint\n        - name: SLS_KEY_ID\n          value:\n          valueFrom:\n            secretKeyRef:\n              name: kubedl-sls-config\n              key: accessKey\n        - name: SLS_KEY_SECRET\n          value:\n          valueFrom:\n            secretKeyRef:\n              name: kubedl-sls-config\n              key: accessSecret\n        - name: SLS_PROJECT\n          value:\n          valueFrom:\n            secretKeyRef:\n              name: kubedl-sls-config\n              key: project\n        - name: SLS_LOG_STORE\n          value:\n          valueFrom:\n            secretKeyRef:\n              name: kubedl-sls-config\n              key: logStore\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id="aliyun-sls-config"\u003eAliyun-sls Config\u003c/h2\u003e\n\u003cp\u003eThe configs defined in the aforementioned \u003ccode\u003esecret\u003c/code\u003e:\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eConfig Name\u003c/th\u003e\n\u003cth\u003eDescription\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eendpoint\u003c/td\u003e\n\u003ctd\u003eThe sls endpoint to connect to\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eaccessKey\u003c/td\u003e\n\u003ctd\u003eThe alicloud account access key\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eaccessSecret\u003c/td\u003e\n\u003ctd\u003eThe alicloud account access secret.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eproject\u003c/td\u003e\n\u003ctd\u003eThe sls project for storing the events\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003elogStore\u003c/td\u003e\n\u003ctd\u003eThe sls log store in the project for storing the events\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id="contributions"\u003eContributions\u003c/h2\u003e\n\u003cp\u003eCurrently, only \u003ccode\u003ealiyun-sls\u003c/code\u003e is supported. You are welcome to contribute your own storage plugin.\u003c/p\u003e\n'},{id:24,href:"https://kubedl.io/docs/help/troubleshooting/",title:"Troubleshooting",description:"Solutions to common problems.",content:'\u003ch2 id="logs"\u003eLogs\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl logs kubedl-controller-manager-0 -n kubedl-system\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id="pod-status"\u003ePod status\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl describe pod kubedl-controller-manager-0 -n kubedl-system\n\u003c/code\u003e\u003c/pre\u003e\n'},{id:25,href:"https://kubedl.io/docs/help/",title:"Help",description:"Help KubeDL.",content:""},{id:26,href:"https://kubedl.io/docs/workloads/mpi/",title:"Mpi",description:"",content:'\u003ch2 id="spec"\u003eSpec\u003c/h2\u003e\n\u003cp\u003eCheck the CRD definition. \u003ca href="https://github.com/alibaba/kubedl/blob/master/apis/training/v1alpha1/mpijob_types.go"\u003eGo -\u0026gt;\u003c/a\u003e\u003c/p\u003e\n'},{id:27,href:"https://kubedl.io/docs/",title:"Docs",description:"Docs Doks.",content:""}];b.add(c),userinput.addEventListener('input',e,!0),suggestions.addEventListener('click',f,!0);function e(){var g=this.value,e=b.search(g,5),f=suggestions.childNodes,h=0,i=e.length,c;for(suggestions.classList.remove('d-none'),e.forEach(function(b){c=document.createElement('div'),c.innerHTML='<a href><span></span><span></span></a>',a=c.querySelector('a'),t=c.querySelector('span:first-child'),d=c.querySelector('span:nth-child(2)'),a.href=b.href,t.textContent=b.title,d.textContent=b.description,suggestions.appendChild(c)});f.length>i;)suggestions.removeChild(f[h])}function f(){while(suggestions.lastChild)suggestions.removeChild(suggestions.lastChild);return!1}})()